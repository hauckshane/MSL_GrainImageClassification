---
title: "Improving the SVM"
author: "Zachary Strennen"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Load Packages
```{r}
library(tidyverse)
```

# Load Data
```{r}
train <- read_csv("train_data.csv")
test_x <- read_csv("test_data_x.csv")
```

# Split train into train and validation
```{r}
set.seed(123)
train_index <- sample(1:nrow(train), 0.8*nrow(train))
train_data <- train[train_index,]
validation_data <- train[-train_index,]

```

# Create matrix of predictors and response
```{r}
# Training set
X_train <- as.matrix(train_data %>% dplyr::select(-Y))
Y_train <- as.matrix(train_data %>% dplyr::select(Y))

# Validation set
X_val <- as.matrix(validation_data %>% dplyr::select(-Y))
Y_val <- as.matrix(validation_data %>% dplyr::select(Y))

```

# Fit a LASSO model 
```{r}
library(glmnet)

# Fit the model
lasso_model <- cv.glmnet(X_train, Y_train, family = "binomial", alpha = 1)

# Make predictions
Y_pred_lasso <- predict(lasso_model, s = "lambda.min", newx = X_val, type = "response")

# Calculate the accuracy
Y_pred_class_lasso <- ifelse(Y_pred_lasso > 0.5, 1, 0)
mean(Y_pred_class_lasso == Y_val)

# Confusion matrix
table(Y_pred_class_lasso, Y_val)

# Log likelihood loss
log_loss <- -mean(Y_val*log(Y_pred_lasso) + (1-Y_val)*log(1-Y_pred_lasso))
log_loss

# Show the coefficients
coef(lasso_model, s = "lambda.min")

```

# Original Support Vector Machine fit
```{r}
library(e1071)

# Fit the model
svm_model <- svm(X_train, Y_train, kernel = "radial")

# Make predictions
Y_pred_svm <- predict(svm_model, X_val)
Y_pred_class_svm <- ifelse(Y_pred_svm > 0.5, 1, 0)

# Calculate the accuracy
mean(Y_pred_class_svm == Y_val)

# Confusion matrix
table(Y_pred_class_svm, Y_val)
```

# Fit SVM with LASSO Selected Variables
```{r}
# Training set with only lasso variables
X_train <- as.matrix(train_data %>% dplyr::select(-c(Y,
                                                     Area,
                                                     MajorAxisLength,
                                                     MinorAxisLength,
                                                     EquivDiameter,
                                                     Compactness,
                                                     ShapeFactor2,
                                                     ShapeFactor3)))
Y_train <- as.matrix(train_data %>% dplyr::select(Y))

# Validation set with only lasso variables
X_val <- as.matrix(validation_data %>% dplyr::select(-c(Y,
                                                     Area,
                                                     MajorAxisLength,
                                                     MinorAxisLength,
                                                     EquivDiameter,
                                                     Compactness,
                                                     ShapeFactor2,
                                                     ShapeFactor3)))
Y_val <- as.matrix(validation_data %>% dplyr::select(Y))

# Fit the model
svm_model <- svm(X_train, Y_train, kernel = "radial")

# Make predictions
Y_pred_svm <- predict(svm_model, X_val)
Y_pred_class_svm <- ifelse(Y_pred_svm > 0.5, 1, 0)

# Calculate the accuracy
mean(Y_pred_class_svm == Y_val)

# Confusion matrix
table(Y_pred_class_svm, Y_val)
```

# Experiment with different tuning parameters
```{r}
# Training set
X_train <- as.matrix(train_data %>% dplyr::select(-Y))
Y_train <- as.matrix(train_data %>% dplyr::select(Y))

# Validation set
X_val <- as.matrix(validation_data %>% dplyr::select(-Y))
Y_val <- as.matrix(validation_data %>% dplyr::select(Y))

# Define ranges for the tuning parameters
costs <- c(0.6, 0.7, 0.8, 0.9, 1)
gammas <- c(0.008, 0.009, 0.01, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045)

# Initialize variables to store the best parameters and highest accuracy
best_cost <- NULL
best_gamma <- NULL
highest_accuracy <- 0

# Loop through all combinations of cost and gamma
for (cost in costs) {
  for (gamma in gammas) {
    # Fit the model with the current combination of parameters
    svm_model <- svm(X_train, Y_train, kernel = "radial", cost = cost, gamma = gamma)
    
    # Make predictions
    Y_pred_svm <- predict(svm_model, X_val)
    Y_pred_class_svm <- ifelse(Y_pred_svm > 0.5, 1, 0)  # Assuming your Y is a binary outcome

    # Calculate the accuracy
    current_accuracy <- mean(Y_pred_class_svm == Y_val)

    # Update the best parameters if the current accuracy is higher
    if (current_accuracy > highest_accuracy) {
      highest_accuracy <- current_accuracy
      best_cost <- cost
      best_gamma <- gamma
    }
  }
}

# Output the best parameters and the highest accuracy
cat("Best Cost: ", best_cost, "\n")
cat("Best Gamma: ", best_gamma, "\n")
cat("Highest Accuracy: ", highest_accuracy, "\n")
```

# Best SVM with tuning parameters
```{r}
# Fit the ideal model
svm_model <- svm(X_train, Y_train, kernel = "radial", cost=0.7, gamma=0.01)

# Make predictions
Y_pred_svm <- predict(svm_model, X_val)
Y_pred_class_svm <- ifelse(Y_pred_svm > 0.5, 1, 0)

# Calculate the accuracy
mean(Y_pred_class_svm == Y_val)

# Confusion matrix
table(Y_pred_class_svm, Y_val)
```


```{r}
# Assuming 'train' is your dataset and 'Y' is the response variable
# Extract features for PCA (exclude the response variable Y)
features <- train[, setdiff(names(train), "Y")]

# Perform PCA, make sure to scale and center the data
pca_result <- prcomp(features, scale. = TRUE, center = TRUE)

# Extract the first two principal components
pc1 <- pca_result$x[, 1]
pc2 <- pca_result$x[, 2]

# Create a data frame for plotting
plot_data <- data.frame(PC1 = pc1, PC2 = pc2, Y = train$Y)

# Generate the plot
ggplot(plot_data, aes(x = PC1, y = PC2, color = factor(Y))) +
  geom_point(alpha = 0.5) +  # alpha for better visibility if points overlap
  labs(color = "Y") +        # Label the color legend
  theme_minimal() +          # Optional: use a minimal theme
  ggtitle("PCA: PC1 vs. PC2 colored by Y")  # Add a title to the plot
```

```{r}
ggplot(plot_data, aes(as.factor(Y))) +
    geom_bar() +
    theme_minimal() +
    labs(title="Distribution of Y Classes",
         y="Count",
         x="Y Classification")
```

```{r}
library(caret)
# Convert predictions to factor for confusion matrix calculation if needed
Y_val <- factor(Y_val, levels = c(0, 1))
Y_pred_class_svm <- factor(Y_pred_class_svm, levels = c(0, 1))

# Confusion matrix
conf_matrix <- confusionMatrix(Y_pred_class_svm, Y_val)
print(conf_matrix)

# Plotting the confusion matrix
library(corrplot)
corrplot::corrplot(conf_matrix$table, is.corr = FALSE)

# Accuracy
accuracy <- sum(Y_pred_class_svm == Y_val) / length(Y_val)
print(paste("Accuracy:", accuracy))

# Calculating precision, recall, and F1-score
precision <- posPredValue(Y_pred_class_svm, Y_val, positive = "1")
recall <- sensitivity(Y_pred_class_svm, Y_val, positive = "1")
f1_score <- (2 * precision * recall) / (precision + recall)

print(paste("Precision:", precision))
print(paste("Recall:", recall))
print(paste("F1 Score:", f1_score))
```

```{r}
library(pROC) 
# Calculate confusion matrix
conf_matrix <- confusionMatrix(as.factor(Y_pred_class_svm), as.factor(Y_val))

# Plot confusion matrix
fourfoldplot(conf_matrix$table, color = c("#CC6666", "#99CC99"), conf.level = 0, margin = 1, main = "Confusion Matrix")

# ROC curve and AUC
roc_obj <- roc(as.numeric(as.factor(Y_val)), as.numeric(Y_pred_svm))
plot(roc_obj, main="ROC Curve")
auc(roc_obj)
```
